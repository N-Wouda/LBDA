\documentclass[12pt, english]{article}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amssymb,amsmath}

\newcommand\mred[1]{%
	\protect\leavevmode
	\begingroup
	\color{red}%
	#1%
	\endgroup
}

\newcommand{\red}{\textcolor{black}}
\newcommand{\redd}{\textcolor{black}}
\newcommand{\reddd}{\textcolor{black}}
\newcommand{\LP}{\text{LP}}
\newcommand{\wpone}{w.p.~$1$ as $S \rightarrow \infty$}
\newcommand{\Qfwd}{\red{\tilde Q}}
\newcommand{\Qalpha}{\red{\hat Q_\alpha}}
\newcommand{\QalphaS}{\hat Q_\alpha^S} 
\newcommand{\QA}{\red{L_{\alpha}^S}}
\newcommand{\valpha}{\red{\hat v_\alpha}}
\newcommand{\valphak}{\red{\hat v_\alpha^k}}
\newcommand{\vfwd}{\red{\tilde v}}
\newcommand{\va}{\red{\nu_\alpha}}
\newcommand{\QR}{\hat{Q}_{\text{out}}^{\tau}}
\newcommand{\QRnext}{\hat{Q}_{\text{out}}^{\tau + 1}}
\newcommand{\fs}{\lfloor s \rfloor}
\newcommand{\lbd}{LBDA($\alpha$)}
\newcommand{\icp}{\text{c}}
\newcommand{\ks}{k_s^{\tau}}   
\newcommand{\tks}{\hat k_s^{\tau}}   
\newcommand{\xalpha}{\red{\hat x_\alpha}}
\newcommand{\xalphaplus}{\red{\hat x_\alpha^+}}

\lstset{
	language=C++,
	basicstyle=\ttfamily\footnotesize,
	frame=lines,
	keywordstyle=\color{blue},
	tabsize=4
}

\title{LBDA+ v1.0 user manual}
\author{
	Niels van der Laan
	\and
	Ward Romeijnders
	\and
	Niels Wouda
}

\date{\today}

\begin{document}
	
\maketitle
\tableofcontents

\clearpage

\section{Introduction}
\label{sec:introduction}
This is the user manual for the computer code of the \emph{loose Benders decomposition algorithm (LBDA)}, introduced in van der Laan and Romeijnders~\cite{vanderLaan2020}. This algorithm approximately solves two-stage mixed-integer recourse models with uncertainty in the right-hand side; see Section~\ref{subsec:model}. 

The algorithm is developed for solving mixed-integer recourse models \emph{with integer decision variables in the second stage}. In fact, the algorithm is based on a Benders decomposition for a convex approximation of the \emph{expected} mixed-integer value function. However, if all decision variables are continuous, then the algorithm reduces to the classical L-shaped algorithm. Moreover, if there are integer decision variables in the first stage, then the master problem is a MIP instead of LP.

For convenience the repository does not only contain the code for LBDA, but also for solving the \emph{deterministic equivalent problem} using Gurobi. In this way the numerical experiments in van der Laan and Romeijnders~\cite{vanderLaan2020} can easily be replicated. Moreover, the code for LBDA is set up in such a way that different types of optimality cuts can easily be added. For example, next to the LBDA cuts and standard Benders cuts used in the paper, also strong Benders cuts are implemented, see Section~\ref{subsec:cut_families}.

The algorithm is coded in C++, free to use and distribute, and also has a Python interface. A reference manual is provided in Section \ref{sec:reference_manual}. Within the algorithm, all linear and integer programs are solved using Gurobi. Moreover, SMPS input is accepted, but the problem data can also be specified manually. See Section~\ref{sec:examples} for examples on how to apply LBDA using both input methods. 

TODO link to repository once public

Before explaining the LBDA code in detail, we first briefly discuss in Section~\ref{subsec:model} the mathematics behind the two-stage mixed-integer recourse models that LBDA solves. This subsection coincides with part of the introduction of van der Laan and Romeijnders \cite{vanderLaan2020}.

\subsection{Two-stage mixed-integer recourse models\label{subsec:model}}

Consider the two-stage mixed-integer recourse model with random right-hand side \begin{equation}\label{etastar}\eta^* := \min_{x}\left\{c^{\top}x + Q(x) :\quad Ax = b,\;x \in X\subseteq \mathbb{R}^{n_1}_+\right\},\end{equation} where the recourse function $Q$ is defined as \begin{equation}\label{defQ}Q(x):=\mathbb{E}_{\omega}\left[ \min_y \left\{   q^{\top}y: Wy = \omega - Tx,\; y \in Y \subseteq \mathbb R^{n_2 }_+\right\}\right]  , \quad x\in \red{X}. \end{equation}This model represents a two-stage decision problem under uncertainty. In the first stage, a decision~$x$ has to be made here-and-now, subject to deterministic constraints $Ax = b$ and random goal constraints $Tx = \omega$. Here, $\omega$ is a \red{continuous or discrete} random vector whose probability distribution is known. In the second stage, the realization of $\omega$ becomes known and any infeasibilities with respect to $Tx = \omega$ have to be repaired. This is modelled by the second-stage problem \begin{equation}\label{vwx}v(\omega,x) := \min_y \left\{   q^{\top}y:Wy = \omega - Tx,\; y \in Y \subseteq  \mathbb{R} ^{n_2 }_+\right\}.\end{equation}The objective in this two-stage recourse model is to minimize the sum of immediate costs $c^{\top}x$ and expected second-stage costs $Q(x) = \mathbb{E}_\omega[v(\omega,x)]$, ${x \in X}$.

Frequently, integrality restrictions are imposed on the first- and second-stage decisions. That is, $X$ and $Y$ are of the form $X = \mathbb Z^{p_1}_+ \times \mathbb{R}^{n_1 - p_1}_+$ and $Y = \mathbb Z^{p_2}_+\times \mathbb{R}^{n_2 - p_2}_+$. Such restrictions arise naturally when modelling real-life problems, for example to model on/off decisions or batch size restrictions. The resulting model is called a mixed-integer recourse (MIR) model.
Such models have many practical applications in for example energy, telecommunication, production planning, and environmental control.

\section{Installation instructions}
\label{sec:installation_instructions}

We explain how to set-up a local copy of the LBDA C++ codebase for use and development. If you only want to use the Python bindings, the package is available on the Python package index as \texttt{lbdapy} for Python 3.8 on Windows and Linux. Make sure the environment variable \texttt{GUROBI\_HOME} points to the Gurobi installation directory, and Armadillo is installed on your computer. 

After following the instruction below, you can either compile your code directly against the source code of our project, or include the headers in \texttt{lbda/include} and link against the \texttt{lbda} static library.

TODO get the package on PyPI and link to it.

\subsection{On Linux}
A development installation is set-up as follows in a Unix/Linux environment. This was tested on Ubuntu 20.04, but should work similarly for many other distributions.
\begin{enumerate}
	\item Clone the repository into some folder. This also clones two submodules, \texttt{pybind11} and \texttt{carma}, which are used to compile the Python bindings.
	
	\item We use \texttt{CMake} as our build tool. It might already be available on your system; if not, it will be installed when we install Armadillo.
	
	\item Install Gurobi. Any recent version should do, but the code was written and tested with Gurobi 9. The header files and libraries should be available in a standard location relative to the \texttt{GUROBI\_HOME} environment variable.
	
	\item For linear algebra, we use the Armadillo library. It is available for many distributions, often via the package manager. The code was written and tested against Armadillo 9.8. You can install the library yourself, or use the \texttt{scripts/install.sh} script to do this for you. It should work on most Debian-based distributions, like Ubuntu. You likely need to be root for the script to work.
	
	\item If everything is set-up correctly, cmake can build \texttt{lbda} from the repository root as \texttt{cmake build lbda}. The resulting Makefile has three targets: \texttt{lbdaexec}, \texttt{lbdapy}, and \texttt{tests}. The first is a stand-alone executable that can read and solve problems specified in the SMPS format. The second is a compiled Python module. The third is a small test suite than can be used to verify a correct installation.
	
	\item If you run \texttt{make lbdaexec}, you should obtain a compiled binary in \texttt{bin/lbdaexec}. Run \texttt{bin/lbdaexec -h} to be greeted by a help message explaining the command-line interface. \texttt{make lbdapy} should result in a compiled Python module in the \texttt{lib} directory. This library can be used together with the Python code in \texttt{lbda/python/lbdapy}. Finally, \texttt{make tests} compiles a suite of tests that can be ran as \texttt{bin/tests}.
\end{enumerate}

\subsection{On Windows}

A Windows set-up can be obtained as follows. TODO

\section{Examples}
\label{sec:examples}

We present two common use cases: solving a known problem given in SMPS format, and specifying a new problem by providing your own matrices and vectors as input. The example code can be ran as-is, either by compiling it against the source files (for the C++ code, where it offers an alternative implementation of the \texttt{main.cpp} file), or by installing the \texttt{lbdapy} package from the package index (for the Python code).

\subsection{Solving a MIR problem using SMPS input}
\label{subsec:solving_smps_example}

Solving a MIR problem specified as a triplet of SMPS files is rather easy. Listings \ref{listing:smps_example_c++} and \ref{listing:smps_example_python} provide some example code, solving a problem provided in the data directory of the Github repository.
\begin{lstlisting}[caption={Solving SMPS input in C++.},
                   label={listing:smps_example_c++}]
#include "deterministicequivalent.h"
#include "masterproblem.h"
#include "problemdata.h"
#include "cutfamilies/loosebenders.h"

int main()
{
	auto problem = ProblemData::fromSmps(
		"data/sslp/sslp_5_25_50");
	
	// Solves the deterministic equivalent formulation.
	DeterministicEquivalent detEqv(problem);
	auto decisions = detEqv.solve();
	
	std::cout << *decisions << '\n';
	std::cout << detEqv.objective() << '\n';
	std::cout << detEqv.firstStageObjective() << '\n';
	std::cout << detEqv.secondStageObjective() << '\n';
	
	// Applies the LBDA.
	arma::vec alpha = arma::zeros(problem.Wmat().n_cols);
	LooseBenders cutFamily(problem, alpha);
	
	MasterProblem master(problem, -1000);
	decisions = master.solveWith(cutFamily);
	
	std::cout << *decisions << '\n';
	std::cout << master.objective() << '\n';
	std::cout << master.firstStageObjective() << '\n';
	std::cout << master.secondStageObjective() << '\n';
}
\end{lstlisting}
\begin{lstlisting}[caption={Solving SMPS input in Python.},
                   label={listing:smps_example_python},
                   language={Python}]
from lbdapy import (DeterministicEquivalent, MasterProblem, 
                    ProblemData)
from lbdapy.cutfamilies import LooseBenders

import numpy as np

problem = ProblemData.from_smps("data/sslp/sslp_5_25_50")

# Solves the deterministic equivalent formulation.
det_eqv = DeterministicEquivalent(problem)
decisions = det_eqv.solve()

print(decisions)
print(det_eqv.objective())
print(det_eqv.first_stage_objective())
print(det_eqv.second_stage_objective())

# Applies the LBDA.
alpha = np.zeros(problem.Wmat().shape[1])
cut_family = LooseBenders(problem, alpha)

master = MasterProblem(problem, lower_bound=-1000)
decisions = master.solve_with(cut_family)

print(decisions)
print(master.objective())
print(master.first_stage_objective())
print(master.second_stage_objective())
\end{lstlisting}
Our SMPS reader is rather strict and might reject reading your files if they do not adhere to the standard \textit{exactly}. If this happens to you, the repository contains a simple Python script you can point to the offending problem set. The script is given in \texttt{data/fix\_faulty\_smps.py}.

In the listings above, we first read the problem data contained in the ``sslp\_5\_25\_50'' files. This is a stochastic server location problem with binary first- and second-stage variables, due to Ntaimo and Sen \cite{ntaimo2005}.  A call to \texttt{fromSmps} (C++) or \texttt{from\_smps} (Python) returns an instance of the class \texttt{ProblemData} (Section \ref{subsec:problem_class}). All solution methods take such a \texttt{ProblemData} instance. Thereafter, we apply two solution methods. First, we construct and solve the deterministic equivalent, and print its optimal first-stage decisions, and objective costs. Then, we solve the same problem with the L-shaped algorithm. We also specify a lower bound of $-1000$. In general, it is important not to forget setting a lower (and possibly upper) bound when using the decomposition. We apply the LBDA cuts of \ref{subsubsec:loose_benders} with $\alpha = 0$. Observe that \emph{the interface for obtaining decisions and objective values is similar for both the decomposition-based \texttt{MasterProblem}, and the direct solution of the \texttt{DeterministicEquivalent}}.

\subsection{Specifying your own problem data}
\label{subsec:own_data_example}

The \texttt{ProblemData} class exposes a constructor, which can be used to specify a problem instance that is not available in SMPS format. This is a bit more involved as there is quite a bit of data to specify. The argument order is given in the reference manual, in Listing \ref{listing:problem_data}.

We solve a small investment problem, originally due to Schultz et al. \cite{schultz1998}. In the first stage, we select $x \in [0, 5]^2$ yielding some immediate revenue. Further revenue is gained from projects $y \in \{0, 1\}^4$ for which investment is done in the second stage, after having observed the random vector $\omega \in [5, 15]^2$, leading to the budget $\omega - x$. As a minimization problem, we have
\[ \min_x \left\{ -\frac{3}{2}x_1 -4 x_2 + \mathbb{E}_\omega [v(\omega, x)]~:~x \in [0, 5]^2 \right\}, \]
where
\[
\begin{split}
	% The second constraint differs between LBDA paper (y_4) and Schultz et al. (2y_4). I follow 
	% the LBDA paper here.
	v(\omega, x) = \min_{y \in Y} \{ -16y_1 -19y_2 -23y_3 - 28y_4~&: \\
							            2y_1 + 3y_2 + 4y_3 + 5y_4 &\le \omega_1 - x_1 \\
					                     6y_1 + y_2 + 3y_3 + y_4 &\le \omega_2 - x_2 \},
\end{split}
\]
and $Y = \{0, 1\}^4$. The problem has relatively complete recourse. We discretize the support of $\omega$ as $\{5, 10, 15\} \times \{5, 10, 15\}$, resulting in $9$ scenarios. Each scenario occurs with fixed probability $p_k = 1 / 9$, $k = 1, \ldots, 9$. The problem is then specified in C++ and Python as given in Listings \ref{listing:custom_example_c++} and \ref{listing:custom_example_python}, respectively.

\begin{lstlisting}[caption={Specifying a custom problem in C++.},
                   label={listing:custom_example_c++}]
#include "deterministicequivalent.h"
#include "masterproblem.h"
#include "problemdata.h"
#include "cutfamilies/loosebenders.h"

int main()
{
    arma::sp_mat A;
	arma::sp_mat T = arma::speye(2, 2);
	
	// This is a quicker way to specify the fully dense 
	// matrix W in our small toy problem, but should not
	// be used when W is large and sparse. 
	arma::mat WDense = {{2, 6}, {3, 1}, {4, 3}, {5, 1}};
	arma::sp_mat W(WDense);
	
	arma::mat scenarios = {{5, 5, 5, 10, 10, 10, 15, 15, 15},
	                       {5, 10, 15, 5, 10, 15, 5, 10, 15}};
	
	arma::vec probs = arma::ones(9) / 9;
	
	arma::Col<char> firstStageSenses;
	arma::Col<char> secondStageSenses = {'<', '<'};
	
	arma::Col<char> firstStageVarTypes = {'C', 'C'};
	arma::Col<char> secondStageVarTypes = {'B', 'B', 'B', 'B'};
	
	arma::vec firstStageCoeffs = {-1.5, -4};
	arma::vec secondStageCoeffs = {-16, -19, -23, -28};
	
	arma::vec firstStageLB = {0, 0};
	arma::vec firstStageUB = {5, 5};
	
	arma::vec secondStageLB = {0, 0, 0, 0};
	arma::vec secondStageUB = {1, 1, 1, 1};
	
	arma::vec firstStageRhs;
	
	ProblemData problem(A,
						T,
						W,
						scenarios,
						probs,
						firstStageSenses,
						secondStageSenses,
						firstStageVarTypes,
						secondStageVarTypes,
						firstStageCoeffs,
						secondStageCoeffs,
						firstStageLB,
						firstStageUB,
						secondStageLB,
						secondStageUB,
						firstStageRhs);

	// Solves the deterministic equivalent formulation.
	DeterministicEquivalent detEqv(problem);
	auto decisions = detEqv.solve();
	
	std::cout << *decisions << '\n';
	std::cout << detEqv.objective() << '\n';
	std::cout << detEqv.firstStageObjective() << '\n';
	std::cout << detEqv.secondStageObjective() << '\n';
	
	// Applies the LBDA.
	arma::vec alpha = arma::zeros(problem.Wmat().n_cols);
	LooseBenders cutFamily(problem, alpha);
	
	MasterProblem master(problem, -100);
	decisions = master.solveWith(cutFamily);
	
	std::cout << *decisions << '\n';
	std::cout << master.objective() << '\n';
	std::cout << master.firstStageObjective() << '\n';
	std::cout << master.secondStageObjective() << '\n';
}
\end{lstlisting}
\begin{lstlisting}[caption={Specifying a custom problem in Python.},
                   label={listing:custom_example_python},
                   language={Python}]
import numpy as np
from lbdapy import (DeterministicEquivalent, MasterProblem, 
					ProblemData)
from lbdapy.cutfamilies import LooseBenders
from scipy.sparse import eye

A = []
T = eye(2, 2, format="csc")
W = [[2, 6], [3, 1], [4, 3], [5, 1]]

scenarios = [[5, 5, 5, 10, 10, 10, 15, 15, 15],
             [5, 10, 15, 5, 10, 15, 5, 10, 15]]

probs = np.ones(9) / 9

first_stage_senses = []
second_stage_senses = ['<', '<']
first_stage_var_types = ['C', 'C']
second_stage_var_types = ['B', 'B', 'B', 'B']

first_stage_coeffs = [-1.5, -4]
second_stage_coeffs = [-16, -19, -23, -28]

first_stage_lb = [0, 0]
first_stage_ub = [5, 5]

second_stage_lb = [0, 0, 0, 0]
second_stage_ub = [1, 1, 1, 1]

first_stage_rhs = []

problem = ProblemData(A,
				      T,
					  W,
					  scenarios,
					  probs,
					  first_stage_senses,
					  second_stage_senses,
					  first_stage_var_types,
					  second_stage_var_types,
					  first_stage_coeffs,
					  second_stage_coeffs,
					  first_stage_lb,
					  first_stage_ub,
					  second_stage_lb,
					  second_stage_ub,
					  first_stage_rhs)

# Solves the deterministic equivalent formulation.
det_eqv = DeterministicEquivalent(problem)
decisions = det_eqv.solve()

print(decisions)
print(det_eqv.objective())
print(det_eqv.first_stage_objective())
print(det_eqv.second_stage_objective())

# Applies the LBDA.
alpha = np.zeros(problem.Wmat().shape[1])
cut_family = LooseBenders(problem, alpha)

master = MasterProblem(problem, lower_bound=-100)
decisions = master.solve_with(cut_family)

print(decisions)
print(master.objective())
print(master.first_stage_objective())
print(master.second_stage_objective())
\end{lstlisting}
Although we did not explicitly mention this in Section \ref{subsec:model}, it is not required to specify the problem with strict equality constraints before applying the LBDA: arbitrary constraint senses are accepted, as shown in the listings above. Observe that the matrices $T$ and $W$ are specified in code as $T^\top$ and $W^\top$: \emph{all three matrices $A$, $T$, and $W$ must be specified in this manner}. We require this for performance reasons, due to the memory lay-out of the numerical library we use. 

Once the problem is specified, the solution method is the same as for the other examples. First we construct the deterministic equivalent and solve it. Then we solve the decomposition using loose Benders' cuts with $\alpha = 0$. Observe that we again specify a lower bound, this time of $-100$.

\section{Reference manual}
\label{sec:reference_manual}

We present a short reference manual of the public methods on classes one might commonly use from the
LBDA+ library. The manual details the C++ interface. The names are similar in the Python interface, but are written in their Pythonic equivalents (\textit{e.g.} \texttt{firstStageObjective} in the C++ code is accessed as \texttt{first\_stage\_objective} in the Python interface). Both interfaces expect similar arguments. For example code in both languages, we refer to Section \ref{sec:examples}.

Our code uses the Armadillo numerical library. Particularly, we often rely on the vector, matrix, and sparse matrix classes offered by Armadillo. Such an Armadillo class can be recognised as belonging to the \texttt{arma} namespace (\textit{e.g.} \texttt{arma::vec} for a real-valued column vector, \texttt{arma::mat} for a real-valued matrix, and \texttt{arma::sp\_mat} for a real-valued sparse matrix in compressed column format). The Armadillo library and documentation are available at \href{http://arma.sourceforge.net/}{their website}.

\subsection{The \texttt{ProblemData} class}
\label{subsec:problem_class}

The \texttt{ProblemData} class contains all data describing a problem instance: the matrices $A$, $T$, and $W$, variable lower- and upper-bounds, constraint senses, objective coefficients, and scenario-specific right-hand sides. All solution methods solve problems described by a \texttt{ProblemData} instance. The public interface is given in Listing \ref{listing:problem_data}, and will be discussed below.
\begin{lstlisting}[caption={Public interface of the \texttt{ProblemData} class.},
                   label={listing:problem_data}]
class ProblemData
{
public:
    ProblemData(arma::sp_mat Amat,
				arma::sp_mat Tmat,
				arma::sp_mat Wmat,
				arma::mat scenarios,
				arma::vec scenarioProbabilities,
				arma::Col<char> firstStageConstrSenses,
				arma::Col<char> secondStageConstrSenses,
				arma::Col<char> firstStageVarTypes,
				arma::Col<char> secondStageVarTypes,
				arma::vec firstStageCoeffs,
				arma::vec secondStageCoeffs,
				arma::vec firstStageLowerBound,
				arma::vec firstStageUpperBound,
				arma::vec secondStageLowerBound,
				arma::vec secondStageUpperBound,
				arma::vec firstStageRhs);

	static ProblemData fromSmps(std::string const &location);
	
	arma::Col<char> const &firstStageConstrSenses() const;
	
	arma::Col<char> const &secondStageConstrSenses() const;
		
	arma::Col<char> const &firstStageVarTypes() const;
	
	arma::Col<char> const &secondStageVarTypes() const;
		
	arma::sp_mat const &Amat() const;
		
	arma::sp_mat const &Tmat() const;
	
	arma::sp_mat const &Wmat() const;
		
	arma::vec const &firstStageCoeffs() const;
	
	arma::vec const &secondStageCoeffs() const;
	
	arma::vec const &firstStageRhs() const;
	
	arma::vec const &firstStageLowerBound() const;
	
	arma::vec const &firstStageUpperBound() const;
	
	arma::vec const &secondStageLowerBound() const;
	
	arma::vec const &secondStageUpperBound() const;
	
	size_t nScenarios() const;
	
	arma::mat const &scenarios() const;
	
	double scenarioProbability(size_t scenario) const;
};
\end{lstlisting}
There are two ways to instantiate the \texttt{ProblemData} class: either by supplying your own vectors and matrices to the constructor, or supplying the filesystem location of an SMPS triplet of files to \texttt{fromSmps}. If one of the three SMSP files does not exist, \texttt{fromSmps} throws a \texttt{std::runtime\_error}.

Most of the member functions are data getters, returning parts of the data that define a two-stage recourse problem. The functions \texttt{Amat()}, \texttt{Tmat()} and \texttt{Wmat()} return references to the (sparse) matrices $A$, $T$, and $W$, respectively. \texttt{nScenarios()} returns the number of scenarios, \texttt{scenarios()} a dense matrix of all scenario right-hand sides (one column for each scenario). Finally, \texttt{scenarioProbability} returns the occurrence probability of the given scenario (number). The use of the other member functions should be clear based on their names.

\subsection{The \texttt{DeterministicEquivalent} class}
\label{subsec:det_eqv_class}

The \texttt{DeterministicEquivalent} class formulates the two-stage recourse problem as a single deterministic (possibly mixed-integer) linear program, and solves it directly. This is sometimes also called the \textit{extensive form}. The public interface is given in Listing \ref{listing:det_eqv}.
\begin{lstlisting}[caption={Public interface of the \texttt{DeterministicEquivalent} class.},
                   label={listing:det_eqv}]
class DeterministicEquivalent
{
public:
	DeterministicEquivalent(ProblemData const &problem);
	
	std::unique_ptr<arma::vec> solve(
		double timeLimit = arma::datum::inf);
	
	bool isOptimal();
	
	double mipGap();
	
	double firstStageObjective();
	
	double secondStageObjective();
	
	double objective() const;
};
\end{lstlisting}
Its constructor takes a \texttt{ProblemData} instance to solve (see Section \ref{subsec:problem_class}). After construction, one can call the \texttt{solve} method, with an optional time limit argument (in seconds). When such an argument is not passed, the time limit defaults to infinity. If the time limit is exceed and no feasible solutions are available, \texttt{solve} throws a \texttt{std::runtime\_error}. This exception is also thrown when the problem is infeasible. The return argument is a (unique) pointer to a vector of first-stage decisions. These decisions are optimal when \texttt{isOptimal} returns true. When \texttt{isOptimal} returns false, the decisions are the best solution found by Gurobi, and \texttt{mipGap} returns the relative optimality gap (as a percentage) of this solution.

After solving the deterministic equivalent, the \texttt{firstStageObjective}, \texttt{secondStageObjective}, and \texttt{objective} methods return the first-stage costs, the expected cost-to-go in the second-stage, and the overall objective cost, respectively.

\subsection{The \texttt{CutFamily} classes}
\label{subsec:cut_families}

The \texttt{CutFamily} abstract class specifies the way a family of cutting planes should be implemented within the Benders' decomposition solution approach. Specifically, a cut family solves a relaxation of the second-stage sub problems to obtain cut coefficients for insertion into the first-stage master problem (see also Section \ref{subsec:master_problem_class}). If $\theta$ is our first-stage approximation of the recourse function $Q$, such an optimality cut takes the form of
\[ \theta \ge \gamma + \beta^\top x, \]
where $\gamma \in \mathbb{R}$ is an intercept and $\beta \in \mathbb{R}^{n_1}$ the slope. The public interface a cut family should implement is given in Listing \ref{listing:cut_family}.
\begin{lstlisting}[caption={Public interface of the \texttt{CutFamily} class.}, 
                   label={listing:cut_family}]
class CutFamily
{
public:
	struct Cut
	{
		arma::vec beta;
		double gamma;
	};
	
	virtual CutFamily::Cut computeCut(arma::vec const &x) = 0;
		
	virtual ~CutFamily() = default;
};
\end{lstlisting}
All that is required of a family of cutting planes is that it implements a method \texttt{computeCut}, which takes the current first-stage decisions and returns suitable cut coefficients, obtained from some relaxation of the sub problems. We now turn to several implementations.

\subsubsection{The \texttt{LpDual} class}
\label{subsubsec:lpdual}

These are the regular Benders' cuts, well-known in stochastic programming from their application in the L-shaped algorithm. The relaxation solved is the LP relaxation of the second-stage sub problem for each of the $K$ scenarios $\omega_k$, $k = 1,\ldots,K$. We denote the optimal objective by $v_{LP}(\omega_k, \bar x)$ for given first-stage solutions $\bar x$, and dual solutions by $\pi_k$. Let
\[ \beta = \sum_{k = 1}^K p_k \beta_k,\]
where $\beta_k = -\pi_k T$.
We choose $\gamma$ as
\begin{equation}
\gamma = \sum_{k = 1}^K \left[ p_k v_{LP}(\omega_k, \bar x) \right] - \beta^\top \bar x.
\label{eq:benders_coeffs}
\end{equation}
The \texttt{LpDual} class implements the \texttt{computeCut} method to return these coefficients. The public interface is straightforward, and given in Listing \ref{listing:lpdual}.
\begin{lstlisting}[caption={Public interface of the \texttt{LpDual} class.}, 
                   label={listing:lpdual}]
class LpDual : public CutFamily
{
public:
	LpDual(ProblemData const &problem);
	
	CutFamily::Cut computeCut(arma::vec const &x) override;
};
\end{lstlisting}

\subsubsection{The \texttt{StrongBenders} class}
\label{subsubsec:strong_benders}

This family is due to Zou et al. \cite{zou2019} and strengthens the regular LP-duality cuts by raising the intercept $\gamma$. As before, we obtain an optimal dual solution $\pi_k$ of the LP relaxation of the $k$\textsuperscript{th} sub problem, for each $k = 1,\ldots,K$, and we compute $\beta_k = -\pi_k T$ and $\beta = \sum_{k = 1}^K p_k \beta_k$. We then solve a Lagrangian relaxation problem at the dual solution of the LP relaxation. This problem is given by
\[ \mathcal{L}(\omega, \beta) := \min_{y, z} \{ q^\top y - \beta^\top z~:~Tz + Wy = \omega, Az = b, y \in Y, z \in X \}. \]
For $\gamma$, we now take
\begin{equation}
\quad \gamma = \sum_{k = 1}^K p_k \mathcal{L}(\omega_k, \beta_k).
\label{eq:strong_benders_coeffs}
\end{equation}
The \texttt{StrongBenders} class implements the \texttt{computeCut} method to return these coefficients. The public interface is again straightforward, and given in Listing \ref{listing:strong_benders}.
\begin{lstlisting}[caption={Public interface of the \texttt{StrongBenders} class.}, 
                   label={listing:strong_benders}]
class StrongBenders : public CutFamily
{
public:
	StrongBenders(ProblemData const &problem);
	
	~StrongBenders() override;
	
	CutFamily::Cut computeCut(arma::vec const &x) override;
};
\end{lstlisting}

\subsubsection{The \texttt{LooseBenders} class}
\label{subsubsec:loose_benders}

The \texttt{LooseBenders} class implements the loose Benders' cuts for the generalized $\alpha$-approximations in~\cite{vanderLaan2020}.
The generalized $\alpha$-approximations and the corresponding loose Benders' cuts depend on a parameter $\alpha$, which is a vector of the same size as $\omega$.
In particular, let $B_k$ denote an optimal basis matrix of $v_{LP}(\omega_k, \bar x)$, and consider the corresponding \emph{Gomory relaxation} $v_{B_k}(\omega_k, \bar x)$, obtained by relaxing the integer restrictions on the basic variables, see~\cite{vanderLaan2020} for details.
Then, $\gamma$ is given by 
\[\gamma = \sum_{k = 1}^K p_k\left(v_{B_k}(\omega_k - \alpha, 0) + \pi_k^\top\alpha \right),\]
and, as before, $\beta = -\sum_{k = 1}^K p_k \pi_k T$. The public interface is given in Listing \ref{listing:loose_benders}.
\begin{lstlisting}[caption={Public interface of the \texttt{LooseBenders} class.}, 
                   label={listing:loose_benders}]
class LooseBenders : public CutFamily
{
public:
	LooseBenders(ProblemData const &problem,
			 	 arma::vec const alpha,
			 	 double timeLimit = 1e3);
	
	~LooseBenders() override;
	
	CutFamily::Cut computeCut(arma::vec const &x) override;
};
\end{lstlisting}
Observe that the \texttt{LooseBenders} class takes a vector $\alpha$ as an argument, and a time limit (in seconds). The time limit applies to the Gomory relaxation $v_{B_k}$, and defaults to $1000$s.

\subsection{The \texttt{MasterProblem} class}
\label{subsec:master_problem_class}

The \texttt{MasterProblem} class solves the two-stage recourse problem by means of decomposition. In particular, it formulates the first-stage master problem, and for each second-stage scenario a suitable sub problem. It then applies a family of cutting planes (Section \ref{subsec:cut_families}) to iteratively approach an optimal solution. The public interface for this class is given in Listing \ref{listing:master_problem}.
\begin{lstlisting}[caption={Public interface of the \texttt{MasterProblem} class.}, 
                   label={listing:master_problem}]
class MasterProblem
{
public:
	MasterProblem(ProblemData const &problem,
				  double lowerBound = 0.,
				  double upperBound = arma::datum::inf);
		
	std::unique_ptr<arma::vec> solveWith(CutFamily &cutFamily,
	                                     double tol = 1e-3);
	
	double firstStageObjective() const;
	
	double secondStageObjective() const;
	
	double objective() const;
};
\end{lstlisting}
Its constructor takes the familiar \texttt{ProblemData} instance, and two optimal arguments providing a lower- and upper-bound on $\theta$. If these are not passed, it is assumed that $0 \le \theta \le \infty$. After construction, one can call the \texttt{solveWith} method, with an appropriate family of cutting planes as an argument. This cut family is then used to derive optimality cuts solving the problem. An optional tolerance argument, \texttt{tol}, can be passed, which specifies the tolerance that should be used when evaluating the optimality of a current first-stage solution. The default tolerance is $0.001$. If the master problem is infeasible, a \texttt{std::runtime\_error} is thrown. In case a sub problem is infeasible, the same exception is thrown; this might happen when we do not have (relatively) complete recourse. The return argument is a (unique) pointer to a vector of near-optimal first-stage decisions.

Once the master problem has been solved, the \texttt{firstStageObjective}, \texttt{secondStageObjective}, and \texttt{objective} methods return the first-stage costs, the expected second-stage costs, and the overall objective cost, respectively.

\clearpage
\bibliographystyle{plain}
\begin{thebibliography}{9}

	\bibitem{vanderLaan2020}
	van der Laan, N., and W.\ Romeijnders, 2020. A loose Benders decomposition algorithm for approximating two-stage mixed-integer recourse models. Accepted for publication in \emph{Mathematical Programming}.

	\bibitem{zou2019}
	Zou, J., S. Ahmed, and X.A. Sun. 2019. Stochastic dual dynamic integer programming. \emph{Mathematical Programming}. 175, pp. 461--502.

	\bibitem{ntaimo2005}
	Ntaimo, L., and S. Sen. 2005. The Million-Variable ``March'' for Stochastic Combinatorial Optimization. \emph{Journal of Global Optimization}. 32, pp. 385-–400.
	
	\bibitem{schultz1998}
	Schultz, R., L. Stougie, and M.H. van der Vlerk. 1998. Solving stochastic programs with integer recourse by enumeration: a framework using Gr\"obner basis reductions. \emph{Mathematical Programming}. 83(1–3), pp. 229-–252.
	
\end{thebibliography}
	
\end{document}